## Language models

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas},
  journal={arXiv preprint arXiv:1301.3781},
  volume={3781},
  year={2013}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the association for computational linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{devlin2018bert,
  title={Bert: Bidirectional encoder representations from transformers},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  pages={15},
  year={2018}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan},
  journal={arXiv preprint arXiv:1907.11692},
  volume={364},
  year={2019}
}

@article{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Z},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

# Coherence measures reference
@inproceedings{mimno-etal-2011-optimizing,
    title = "Optimizing Semantic Coherence in Topic Models",
    author = "Mimno, David  and
      Wallach, Hanna  and
      Talley, Edmund  and
      Leenders, Miriam  and
      McCallum, Andrew",
    editor = "Barzilay, Regina  and
      Johnson, Mark",
    booktitle = "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2011",
    address = "Edinburgh, Scotland, UK.",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D11-1024",
    pages = "262--272",
}

@inproceedings{roder2015exploring,
  title={Exploring the space of topic coherence measures},
  author={R{\"o}der, Michael and Both, Andreas and Hinneburg, Alexander},
  booktitle={Proceedings of the eighth ACM international conference on Web search and data mining},
  pages={399--408},
  year={2015}
}

@article{bouma2009normalized,
author = {Bouma, Gerlof},
year = {2009},
month = {01},
pages = {},
title = {Normalized (Pointwise) Mutual Information in Collocation Extraction},
journal = {Proceedings of the Biennial GSCL Conference 2009}
}

@inproceedings{newman2010automatic,
  title={Automatic evaluation of topic coherence},
  author={Newman, David and Lau, Jey Han and Grieser, Karl and Baldwin, Timothy},
  booktitle={Human language technologies: The 2010 annual conference of the North American chapter of the association for computational linguistics},
  pages={100--108},
  year={2010}
}

@inproceedings{nikolenko2016topic,
  title={Topic quality metrics based on distributed word representations},
  author={Nikolenko, Sergey I},
  booktitle={Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval},
  pages={1029--1032},
  year={2016}
}

# Specific References

@inproceedings{aletras_evaluating_2013,
	address = {Potsdam, Germany},
	title = {Evaluating {Topic} {Coherence} {Using} {Distributional} {Semantics}},
	url = {https://aclanthology.org/W13-0102},
	urldate = {2024-10-20},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Computational} {Semantics} ({IWCS} 2013) – {Long} {Papers}},
	publisher = {Association for Computational Linguistics},
	author = {Aletras, Nikolaos and Stevenson, Mark},
	editor = {Koller, Alexander and Erk, Katrin},
	month = mar,
	year = {2013},
	pages = {13--22},
	file = {Full Text PDF:files/96/Aletras y Stevenson - 2013 - Evaluating Topic Coherence Using Distributional Se.pdf:application/pdf},
}

@inproceedings{nikolenko_topic_2016,
	address = {New York, NY, USA},
	series = {{SIGIR} '16},
	title = {Topic {Quality} {Metrics} {Based} on {Distributed} {Word} {Representations}},
	isbn = {978-1-4503-4069-4},
	url = {https://dl.acm.org/doi/10.1145/2911451.2914720},
	doi = {10.1145/2911451.2914720},
	abstract = {Automated evaluation of topic quality remains an important unsolved problem in topic modeling and represents a major obstacle for development and evaluation of new topic models. Previous attempts at the problem have been formulated as variations on the coherence and/or mutual information of top words in a topic. In this work, we propose several new metrics for evaluating topic quality with the help of distributed word representations; our experiments suggest that the new metrics are a better match for human judgement, which is the gold standard in this case, than previously developed approaches.},
	urldate = {2024-10-22},
	booktitle = {Proceedings of the 39th {International} {ACM} {SIGIR} conference on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Nikolenko, Sergey I.},
	month = jul,
	year = {2016},
	pages = {1029--1032},
	file = {Full Text PDF:C\:\\Users\\manuc\\Zotero\\storage\\33M7TCXJ\\Nikolenko - 2016 - Topic Quality Metrics Based on Distributed Word Re.pdf:application/pdf},
}

@inproceedings{doogan_topic_2021,
	address = {Online},
	title = {Topic {Model} or {Topic} {Twaddle}? {Re}-evaluating {Semantic} {Interpretability} {Measures}},
	shorttitle = {Topic {Model} or {Topic} {Twaddle}?},
	url = {https://aclanthology.org/2021.naacl-main.300},
	doi = {10.18653/v1/2021.naacl-main.300},
	abstract = {When developing topic models, a critical question that should be asked is: How well will this model work in an applied setting? Because standard performance evaluation of topic interpretability uses automated measures modeled on human evaluation tests that are dissimilar to applied usage, these models’ generalizability remains in question. In this paper, we probe the issue of validity in topic model evaluation and assess how informative coherence measures are for specialized collections used in an applied setting. Informed by the literature, we propose four understandings of interpretability. We evaluate these using a novel experimental framework reﬂective of varied applied settings, including human evaluations using open labeling, typical of applied research. These evaluations show that for some specialized collections, standard coherence measures may not inform the most appropriate topic model or the optimal number of topics, and current interpretability performance validation methods are challenged as a means to conﬁrm model quality in the absence of ground truth data.},
	language = {en},
	urldate = {2024-10-05},
	booktitle = {Proceedings of the 2021 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Doogan, Caitlin and Buntine, Wray},
	year = {2021},
	pages = {3824--3848},
	file = {PDF:C\:\\Users\\manuc\\Zotero\\storage\\BX79V2RP\\Doogan y Buntine - 2021 - Topic Model or Topic Twaddle Re-evaluating Semantic Interpretability Measures.pdf:application/pdf},
}
